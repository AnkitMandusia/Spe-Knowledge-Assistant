{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GKLEnz81KFSN"
      },
      "outputs": [],
      "source": [
        "# # ================================\n",
        "# # STEP 1: Install Dependencies\n",
        "# # ================================\n",
        "\n",
        "%%capture\n",
        "# This command forces an upgrade of the core conflicting library (NumPy).\n",
        "!pip install --upgrade -q pip numpy\n",
        "\n",
        "# Now, install the rest of the application's dependencies\n",
        "!pip install -q fastapi uvicorn python-multipart PyMuPDF \"pinecone-client>=3.2.2\" \"langchain>=0.1.16\" \"langchain-community>=0.0.32\" langchain-huggingface langchain-pinecone \"transformers>=4.40.1\" torch torchvision torchaudio --upgrade \"accelerate>=0.29.3\" \"pyngrok>=7.1.6\" \"nest_asyncio>=1.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SXnveflaguhy"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade llama-index langchain langchain-huggingface transformers sentence-transformers\n",
        "!pip uninstall -y llama-index\n",
        "!pip install --upgrade langchain transformers sentence-transformers pinecone-client\n",
        "!pip install \"llama-index==0.5.6\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5C8WgO7nv1s"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "## Install a specific, known-good set of libraries to ensure full compatibility.\n",
        "!pip install -q fastapi uvicorn python-multipart PyMuPDF \"pinecone-client==3.2.2\" \"langchain==0.2.5\" \"langchain-community==0.2.5\" \"langchain-huggingface==0.0.3\" \"langchain-pinecone==0.1.1\" \"transformers==4.40.1\" \"torch==2.3.1\" \"torchvision==0.18.1\" \"torchaudio==2.3.1\" --index-url https://download.pytorch.org/whl/cu121 \"accelerate==0.29.3\" \"pyngrok>=7.1.6\" \"nest_asyncio>=1.6.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bjAV7Qusu96u"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install -q bitsandbytes==0.43.1\n",
        "!pip install -q triton\n",
        "!pip install --upgrade bitsandbytes\n",
        "# Run this cell once to install the Tesseract OCR engine\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS_v2jGwIlU_"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken -KEY-\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaQ82_enM4aT"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# This will display a login widget to authenticate your notebook.\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P9hiM7BMYEwy"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# IMPORTS & SETUP\n",
        "# ================================\n",
        "import os\n",
        "import logging\n",
        "import nest_asyncio\n",
        "import fitz  # PyMuPDF\n",
        "from pyngrok import ngrok\n",
        "import uuid\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "from fastapi import FastAPI, UploadFile, File, Form, HTTPException\n",
        "from fastapi.responses import HTMLResponse\n",
        "from pydantic import BaseModel\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# LangChain Imports\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Apply nest_asyncio to allow asyncio to run in a notebook environment\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Load environment variables from a .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# ================================\n",
        "# CONFIGURATION\n",
        "# ================================\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "# Securely get API keys from environment variables\n",
        "HF_KEY = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
        "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
        "\n",
        "if not HF_KEY or not PINECONE_API_KEY:\n",
        "    logging.warning(\"⚠️ Hugging Face or Pinecone API keys are not set. Please set them as environment variables.\")\n",
        "\n",
        "PINECONE_INDEX_NAME = \"knowledge-assistant\"\n",
        "app = FastAPI()\n",
        "\n",
        "# ================================\n",
        "# HTML FRONTEND (With Session Management)\n",
        "# ================================\n",
        "html_content = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Spe | Knowledge Assistant</title>\n",
        "    <style>\n",
        "        :root {\n",
        "            --bg-color: #0c0a1d;\n",
        "            --container-bg: rgba(26, 16, 60, 0.85);\n",
        "            --primary-accent: #9d55f5;\n",
        "            --secondary-accent: #f555b5;\n",
        "            --text-color: #e0e0e0;\n",
        "            --text-color-dark: #1a103c;\n",
        "            --border-color: #4d3e8c;\n",
        "            --user-msg-bg: #4a3a8a;\n",
        "            --assistant-msg-bg: #3a2d7a;\n",
        "            --font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica, Arial, sans-serif;\n",
        "            --border-radius: 16px;\n",
        "            --box-shadow: 0 10px 30px rgba(0,0,0,0.4);\n",
        "        }\n",
        "        body {\n",
        "            font-family: var(--font-family); margin: 0; color: var(--text-color);\n",
        "            display: flex; justify-content: center; align-items: center;\n",
        "            height: 100vh; padding: 16px; box-sizing: border-box;\n",
        "            background: var(--bg-color);\n",
        "            overflow: hidden; /* Prevents scrollbars from the animated background */\n",
        "        }\n",
        "        .stars {\n",
        "            position: fixed; top: 0; left: 0; width: 100%; height: 100%;\n",
        "            background-image:\n",
        "                radial-gradient(2px 2px at 20px 30px, #eee, rgba(0,0,0,0)),\n",
        "                radial-gradient(2px 2px at 40px 70px, #fff, rgba(0,0,0,0)),\n",
        "                radial-gradient(2px 2px at 50px 160px, #ddd, rgba(0,0,0,0)),\n",
        "                radial-gradient(2px 2px at 90px 40px, #fff, rgba(0,0,0,0)),\n",
        "                radial-gradient(2px 2px at 130px 80px, #fff, rgba(0,0,0,0)),\n",
        "                radial-gradient(2px 2px at 160px 120px, #ddd, rgba(0,0,0,0));\n",
        "            background-repeat: repeat;\n",
        "            background-size: 200px 200px;\n",
        "            animation: zoom 15s infinite;\n",
        "            opacity: 0;\n",
        "            animation-delay: 1s;\n",
        "            animation-timing-function: linear;\n",
        "        }\n",
        "        @keyframes zoom {\n",
        "            0% { transform: scale(1); opacity: 0; }\n",
        "            50% { opacity: 0.7; }\n",
        "            100% { transform: scale(2); opacity: 0; }\n",
        "        }\n",
        "        .chat-container {\n",
        "            width: 100%; max-width: 800px; height: 95vh; display: flex;\n",
        "            flex-direction: column; background: var(--container-bg); border-radius: var(--border-radius);\n",
        "            box-shadow: var(--box-shadow); overflow: hidden; border: 1px solid var(--border-color);\n",
        "            backdrop-filter: blur(10px); z-index: 1;\n",
        "        }\n",
        "        header {\n",
        "            background: linear-gradient(90deg, var(--primary-accent), var(--secondary-accent));\n",
        "            padding: 16px; text-align: center; font-size: 1.25rem; font-weight: 600;\n",
        "            display: flex; align-items: center; justify-content: center; gap: 12px;\n",
        "            color: var(--text-color-dark); text-shadow: 1px 1px 2px rgba(0,0,0,0.2);\n",
        "            flex-shrink: 0;\n",
        "        }\n",
        "        .chat-box { flex-grow: 1; padding: 24px; overflow-y: auto; display: flex; flex-direction: column; gap: 16px; }\n",
        "        .message { display: flex; align-items: flex-start; gap: 12px; max-width: 85%; animation: fadeIn 0.3s ease-in-out; }\n",
        "        @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }\n",
        "        .message .avatar { width: 40px; height: 40px; border-radius: 50%; display: flex; justify-content: center; align-items: center; font-weight: bold; flex-shrink: 0; }\n",
        "        .message .content { padding: 12px 16px; border-radius: var(--border-radius); white-space: pre-wrap; word-wrap: break-word; }\n",
        "        .user-message { align-self: flex-end; flex-direction: row-reverse; }\n",
        "        .user-message .avatar { background-color: var(--secondary-accent); color: var(--text-color-dark); }\n",
        "        .user-message .content { background-color: var(--user-msg-bg); border-bottom-right-radius: 4px; }\n",
        "        .assistant-message { align-self: flex-start; }\n",
        "        .assistant-message .avatar { background-color: var(--primary-accent); color: var(--text-color-dark); }\n",
        "        .assistant-message .content { background-color: var(--assistant-msg-bg); border-bottom-left-radius: 4px; }\n",
        "        .sources { margin-top: 12px; font-size: 0.85em; }\n",
        "        .sources-title { font-weight: bold; margin-bottom: 4px; color: var(--secondary-accent); }\n",
        "        .source-tag { display: inline-block; background-color: var(--user-msg-bg); padding: 3px 10px; border-radius: 12px; margin: 0 5px 5px 0; font-size: 0.8rem; }\n",
        "        .chat-input { display: flex; padding: 16px; border-top: 1px solid var(--border-color); gap: 10px; align-items: center; flex-shrink: 0; }\n",
        "        .chat-input input {\n",
        "            flex-grow: 1; padding: 12px 18px; border: 1px solid var(--border-color); border-radius: 25px;\n",
        "            font-size: 1rem; background-color: var(--bg-color); color: var(--text-color); transition: all 0.2s ease;\n",
        "        }\n",
        "        .chat-input input:focus { outline: none; border-color: var(--primary-accent); box-shadow: 0 0 0 3px rgba(157, 85, 245, 0.4); }\n",
        "        .chat-input button {\n",
        "            width: 45px; height: 45px; border: none; border-radius: 50%;\n",
        "            cursor: pointer; display: flex; justify-content: center; align-items: center; transition: all 0.2s ease; flex-shrink: 0;\n",
        "        }\n",
        "        .chat-input button.send-button { background-color: var(--primary-accent); color: var(--text-color-dark); }\n",
        "        .chat-input button.send-button:hover { background-color: #b37af8; transform: scale(1.1); }\n",
        "        .chat-input button:disabled { background-color: #555; cursor: not-allowed; transform: none; }\n",
        "        .chat-input button.stop-button { background-color: var(--secondary-accent); color: var(--text-color-dark); }\n",
        "        .chat-input button.stop-button:hover { background-color: #f87ac5; transform: scale(1.1); }\n",
        "        .chat-input button.add-button { background-color: var(--user-msg-bg); color: var(--text-color); }\n",
        "        .chat-input button.add-button:hover { background-color: #6a5a9a; transform: scale(1.1); }\n",
        "        .upload-overlay {\n",
        "            position: absolute; inset: 0; background: rgba(12, 10, 29, 0.95); backdrop-filter: blur(5px); z-index: 10;\n",
        "            display: flex; justify-content: center; align-items: center; flex-direction: column; padding: 24px;\n",
        "        }\n",
        "        .upload-container { width: 100%; max-width: 500px; text-align: center; background: var(--container-bg); padding: 30px; border-radius: var(--border-radius); border: 1px solid var(--border-color); }\n",
        "        #drop-zone { border: 2px dashed var(--border-color); border-radius: var(--border-radius); padding: 40px; color: var(--accent-color); transition: border-color 0.3s, background-color 0.3s; box-sizing: border-box; }\n",
        "        #drop-zone.dragover { border-color: var(--primary-accent); background-color: rgba(157, 85, 245, 0.1); }\n",
        "        #file-list { margin-top: 16px; max-height: 150px; overflow-y: auto; text-align: left; font-size: 0.9em; }\n",
        "        .primary-button { background: linear-gradient(90deg, var(--primary-accent), var(--secondary-accent)); color: var(--text-color-dark); padding: 12px 24px; font-size: 1.1rem; border: none; border-radius: 25px; cursor: pointer; font-weight: 600; transition: all 0.2s ease; }\n",
        "        .primary-button:hover { transform: scale(1.05); box-shadow: 0 5px 15px rgba(0,0,0,0.3); }\n",
        "        .primary-button:disabled { background: #555; color: #888; cursor: not-allowed; transform: none; box-shadow: none; }\n",
        "        .heartbeat-loader { width: 50px; height: 50px; position: relative; }\n",
        "        .heartbeat-loader svg { width: 100%; height: 100%; position: absolute; top: 0; left: 0; }\n",
        "        .heartbeat-loader path {\n",
        "            stroke: var(--secondary-accent); stroke-width: 3; fill: transparent;\n",
        "            stroke-dasharray: 1000; stroke-dashoffset: 1000;\n",
        "            animation: draw 2s linear infinite, pulse 2s ease-in-out infinite;\n",
        "        }\n",
        "        @keyframes draw { to { stroke-dashoffset: 0; } }\n",
        "        @keyframes pulse {\n",
        "            0%, 100% { transform: scale(0.95); }\n",
        "            50% { transform: scale(1.1); }\n",
        "        }\n",
        "        @media (max-width: 768px) {\n",
        "            body { padding: 0; }\n",
        "            .chat-container {\n",
        "                height: 100vh; max-height: none;\n",
        "                border-radius: 0; border: none;\n",
        "            }\n",
        "            .chat-box { padding: 16px; }\n",
        "            .chat-input { padding: 12px; }\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"stars\"></div>\n",
        "    <div class=\"chat-container\">\n",
        "        <header>\n",
        "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M12 22a10 10 0 1 0 0-20 10 10 0 0 0 0 20Z\"/><path d=\"M12 16a4 4 0 1 0 0-8 4 4 0 0 0 0 8Z\"/><path d=\"M12 12v1\"/><path d=\"M12 8V7\"/><path d=\"m16 12 1-.01\"/><path d=\"m8 12-1-.01\"/></svg>\n",
        "            <span>Spe - Knowledge Assistant</span>\n",
        "        </header>\n",
        "        <div class=\"chat-box\" id=\"chat-box\"></div>\n",
        "        <div class=\"chat-input\">\n",
        "            <button id=\"add-button\" onclick=\"startOver()\" class=\"add-button\" style=\"display: none;\" title=\"Upload new documents\">\n",
        "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><line x1=\"12\" y1=\"5\" x2=\"12\" y2=\"19\"></line><line x1=\"5\" y1=\"12\" x2=\"19\" y2=\"12\"></line></svg>\n",
        "            </button>\n",
        "            <input type=\"text\" id=\"query-input\" placeholder=\"Upload documents to begin...\" disabled>\n",
        "            <button id=\"send-button\" onclick=\"askQuestion()\" class=\"send-button\" disabled>\n",
        "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><line x1=\"22\" y1=\"2\" x2=\"11\" y2=\"13\"></line><polygon points=\"22 2 15 22 11 13 2 9 22 2\"></polygon></svg>\n",
        "            </button>\n",
        "            <button id=\"stop-button\" onclick=\"stopGeneration()\" class=\"stop-button\" style=\"display: none;\" title=\"Stop generation\">\n",
        "                <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"currentColor\" stroke=\"none\"><path d=\"M6 6h12v12H6z\"></path></svg>\n",
        "            </button>\n",
        "        </div>\n",
        "        <div class=\"upload-overlay\" id=\"upload-overlay\">\n",
        "            <div class=\"upload-container\">\n",
        "                <h2>Upload Knowledge Base</h2>\n",
        "                <p>Begin by uploading PDF or image files.</p>\n",
        "                <div id=\"drop-zone\">\n",
        "                    <p><strong>Drag & Drop files here</strong> or</p>\n",
        "                    <input type=\"file\" id=\"file-upload\" multiple accept=\".pdf,.png,.jpg,.jpeg\" hidden>\n",
        "                    <button onclick=\"document.getElementById('file-upload').click()\" class=\"primary-button\" style=\"background: var(--assistant-msg-bg); color: white;\">Select Files</button>\n",
        "                    <div id=\"file-list\"></div>\n",
        "                </div>\n",
        "                <button id=\"upload-button\" onclick=\"uploadFiles()\" class=\"primary-button\" style=\"margin-top: 20px;\" disabled>Upload & Process</button>\n",
        "                <div id=\"upload-status\" style=\"margin-top: 16px;\"></div>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    <script>\n",
        "        const chatBox = document.getElementById('chat-box');\n",
        "        const queryInput = document.getElementById('query-input');\n",
        "        const sendButton = document.getElementById('send-button');\n",
        "        const stopButton = document.getElementById('stop-button');\n",
        "        const uploadOverlay = document.getElementById('upload-overlay');\n",
        "        const dropZone = document.getElementById('drop-zone');\n",
        "        const fileInput = document.getElementById('file-upload');\n",
        "        const fileList = document.getElementById('file-list');\n",
        "        const uploadButton = document.getElementById('upload-button');\n",
        "        const uploadStatus = document.getElementById('upload-status');\n",
        "        const addButton = document.getElementById('add-button');\n",
        "\n",
        "        let currentTypewriterInterval = null;\n",
        "\n",
        "        // ✅ NEW: Generate a UUID for the session\n",
        "        const uuidv4 = () => {\n",
        "            return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g, c =>\n",
        "                (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)\n",
        "            );\n",
        "        };\n",
        "        let currentSessionId = uuidv4();\n",
        "\n",
        "        dropZone.addEventListener('dragover', (e) => { e.preventDefault(); dropZone.classList.add('dragover'); });\n",
        "        dropZone.addEventListener('dragleave', () => dropZone.classList.remove('dragover'));\n",
        "        dropZone.addEventListener('drop', (e) => { e.preventDefault(); dropZone.classList.remove('dragover'); handleFiles(e.dataTransfer.files); });\n",
        "        fileInput.addEventListener('change', () => handleFiles(fileInput.files));\n",
        "\n",
        "        function handleFiles(files) {\n",
        "            fileList.innerHTML = '';\n",
        "            Array.from(files).forEach(file => fileList.innerHTML += `<p style=\"margin: 4px 0;\">${file.name}</p>`);\n",
        "            uploadButton.disabled = files.length === 0;\n",
        "        }\n",
        "\n",
        "        function startOver() {\n",
        "            // ✅ NEW: Generate a new session ID to start fresh\n",
        "            currentSessionId = uuidv4();\n",
        "\n",
        "            uploadOverlay.style.display = 'flex';\n",
        "            chatBox.innerHTML = '';\n",
        "            queryInput.disabled = true;\n",
        "            queryInput.placeholder = 'Upload new documents to begin...';\n",
        "            sendButton.disabled = true;\n",
        "            addButton.style.display = 'none';\n",
        "            fileInput.value = '';\n",
        "            fileList.innerHTML = '';\n",
        "            uploadButton.disabled = true;\n",
        "            uploadStatus.innerHTML = '';\n",
        "        }\n",
        "\n",
        "        async function uploadFiles() {\n",
        "            const files = Array.from(fileInput.files);\n",
        "            if (files.length === 0) return;\n",
        "\n",
        "            const formData = new FormData();\n",
        "            files.forEach(file => formData.append('files', file));\n",
        "            // ✅ NEW: Send the session ID with the upload request\n",
        "            formData.append('session_id', currentSessionId);\n",
        "\n",
        "            uploadStatus.innerHTML = `\n",
        "                <div class=\"heartbeat-loader\">\n",
        "                    <svg viewBox=\"0 0 100 100\">\n",
        "                        <path d=\"M 90 40 C 90 20 70 20 70 40 C 70 50 90 65 90 80 C 90 95 70 95 70 80 C 50 65 50 50 50 40 C 50 20 30 20 30 40 C 30 50 10 65 10 80 C 10 95 30 95 30 80 C 50 65 50 50 50 40\" />\n",
        "                    </svg>\n",
        "                </div>\n",
        "                <p>Processing files...</p>`;\n",
        "            uploadButton.disabled = true;\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/upload/', { method: 'POST', body: formData });\n",
        "                const result = await response.json();\n",
        "                if (!response.ok) throw new Error(result.detail || 'Upload failed.');\n",
        "\n",
        "                uploadOverlay.style.display = 'none';\n",
        "                queryInput.disabled = false;\n",
        "                sendButton.disabled = false;\n",
        "                addButton.style.display = 'flex';\n",
        "                queryInput.placeholder = 'Ask a question about your documents...';\n",
        "                queryInput.focus();\n",
        "                addMessage('assistant', 'Hello! Your documents are ready. How can I help you?');\n",
        "            } catch (error) {\n",
        "                const errorMsg = `❌ Error: ${error.message}`;\n",
        "                uploadStatus.innerHTML = `<span style=\"color: #ff6b6b;\">${errorMsg}</span>`;\n",
        "                uploadButton.disabled = false;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function askQuestion() {\n",
        "            const query = queryInput.value.trim();\n",
        "            if (!query) return;\n",
        "\n",
        "            addMessage('user', query);\n",
        "            queryInput.value = '';\n",
        "            queryInput.focus();\n",
        "\n",
        "            sendButton.style.display = 'none';\n",
        "            stopButton.style.display = 'flex';\n",
        "\n",
        "            const aiMessageContent = addMessage('assistant', '');\n",
        "\n",
        "            try {\n",
        "                // ✅ NEW: Send the session ID with the query\n",
        "                const payload = {\n",
        "                    query: query,\n",
        "                    session_id: currentSessionId\n",
        "                };\n",
        "                const response = await fetch('/query/', {\n",
        "                    method: 'POST',\n",
        "                    headers: { 'Content-Type': 'application/json' },\n",
        "                    body: JSON.stringify(payload),\n",
        "                });\n",
        "                const result = await response.json();\n",
        "                if (!response.ok) throw new Error(result.detail || 'Query failed.');\n",
        "\n",
        "                typewriterEffect(aiMessageContent, result.answer, result.sources);\n",
        "            } catch (error) {\n",
        "                typewriterEffect(aiMessageContent, `❌ An error occurred: ${error.message}`);\n",
        "            }\n",
        "        }\n",
        "\n",
        "        function stopGeneration() {\n",
        "            if (currentTypewriterInterval) {\n",
        "                clearInterval(currentTypewriterInterval);\n",
        "                currentTypewriterInterval = null;\n",
        "                const lastMessageContent = document.querySelector('.assistant-message:last-child .content');\n",
        "                if (lastMessageContent) {\n",
        "                    lastMessageContent.innerHTML += '... [Stopped]';\n",
        "                }\n",
        "            }\n",
        "            resetButtons();\n",
        "        }\n",
        "\n",
        "        function resetButtons() {\n",
        "            stopButton.style.display = 'none';\n",
        "            sendButton.style.display = 'flex';\n",
        "        }\n",
        "\n",
        "        function typewriterEffect(element, text, sources = []) {\n",
        "            const words = text.split(' ');\n",
        "            let i = 0;\n",
        "            element.textContent = '';\n",
        "\n",
        "            currentTypewriterInterval = setInterval(() => {\n",
        "                if (i < words.length) {\n",
        "                    element.textContent += words[i] + ' ';\n",
        "                    chatBox.scrollTop = chatBox.scrollHeight;\n",
        "                    i++;\n",
        "                } else {\n",
        "                    clearInterval(currentTypewriterInterval);\n",
        "                    currentTypewriterInterval = null;\n",
        "                    if (sources && sources.length > 0) {\n",
        "                        const sourcesDiv = document.createElement('div');\n",
        "                        sourcesDiv.classList.add('sources');\n",
        "                        sourcesDiv.innerHTML = `<div class=\"sources-title\">Sources:</div>`;\n",
        "                        sources.forEach(source => {\n",
        "                            sourcesDiv.innerHTML += `<span class=\"source-tag\">${source}</span>`;\n",
        "                        });\n",
        "                        element.appendChild(sourcesDiv);\n",
        "                        chatBox.scrollTop = chatBox.scrollHeight;\n",
        "                    }\n",
        "                    resetButtons();\n",
        "                }\n",
        "            }, 50);\n",
        "        }\n",
        "\n",
        "        function addMessage(sender, text) {\n",
        "            const messageDiv = document.createElement('div');\n",
        "            messageDiv.classList.add('message', `${sender}-message`);\n",
        "\n",
        "            const avatar = document.createElement('div');\n",
        "            avatar.classList.add('avatar');\n",
        "            avatar.textContent = sender === 'user' ? 'You' : 'S';\n",
        "\n",
        "            const content = document.createElement('div');\n",
        "            content.classList.add('content');\n",
        "            if (text) {\n",
        "                content.textContent = text;\n",
        "            }\n",
        "\n",
        "            messageDiv.appendChild(avatar);\n",
        "            messageDiv.appendChild(content);\n",
        "            chatBox.appendChild(messageDiv);\n",
        "            chatBox.scrollTop = chatBox.scrollHeight;\n",
        "            return content;\n",
        "        }\n",
        "\n",
        "        queryInput.addEventListener('keypress', (e) => {\n",
        "            if (e.key === 'Enter' && !e.shiftKey) {\n",
        "                e.preventDefault();\n",
        "                if (!sendButton.disabled) askQuestion();\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ================================\n",
        "# INITIALIZE MODELS AND SERVICES\n",
        "# ================================\n",
        "try:\n",
        "    logging.info(\"Initializing models and services...\")\n",
        "\n",
        "    embed_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
        "    vector_store = PineconeVectorStore.from_existing_index(\n",
        "        index_name=PINECONE_INDEX_NAME,\n",
        "        embedding=embed_model\n",
        "    )\n",
        "\n",
        "    logging.info(\"Loading local LLM (Google Gemma 7B)...\")\n",
        "    model_id = \"meta-llama/Llama-2-13b-chat-hf\"\n",
        "\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_use_double_quant=True\n",
        "    )\n",
        "\n",
        "    # Load tokenizer & model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_id,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",          # accelerate handles placement\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # ================================\n",
        "    # Create text-generation pipeline\n",
        "    # ================================\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.1\n",
        "        # 🚫 No \"device\" arg here\n",
        "    )\n",
        "\n",
        "    # ================================\n",
        "    # Example usage\n",
        "    # ================================\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Summarize the advantages of using quantization in LLMs.\"}\n",
        "    ]\n",
        "\n",
        "    # Apply LLaMA chat template\n",
        "    tokenized_chat = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        tokenized_chat,\n",
        "        max_new_tokens=512,\n",
        "        eos_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=50)\n",
        "\n",
        "    MODELS_LOADED = True\n",
        "    logging.info(\"✅ Initialization complete.\")\n",
        "except Exception as e:\n",
        "    MODELS_LOADED = False\n",
        "    llm = None\n",
        "    vector_store = None\n",
        "    text_splitter = None\n",
        "    logging.error(f\"🔥 Failed to initialize models: {e}\")\n",
        "    logging.error(\"The application will not be able to answer questions. Please check your API keys and runtime.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# API ENDPOINTS (Updated for OCR and Session Handling)\n",
        "# ================================\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def root():\n",
        "    return HTMLResponse(content=html_content)\n",
        "\n",
        "@app.post(\"/upload/\")\n",
        "async def upload(files: list[UploadFile] = File(...), session_id: str = Form(...)):\n",
        "    if not MODELS_LOADED:\n",
        "        raise HTTPException(status_code=503, detail=\"Model services are not available.\")\n",
        "    if not files:\n",
        "        raise HTTPException(status_code=400, detail=\"No files were sent.\")\n",
        "    if not session_id:\n",
        "        raise HTTPException(status_code=400, detail=\"A session ID is required.\")\n",
        "\n",
        "    logging.info(f\"Starting upload for session ID: {session_id}\")\n",
        "    all_docs = []\n",
        "    for file in files:\n",
        "        file_content = await file.read()\n",
        "        file_name = file.filename\n",
        "        try:\n",
        "            if file_name.lower().endswith(\".pdf\"):\n",
        "                with fitz.open(stream=file_content, filetype=\"pdf\") as doc:\n",
        "                    for i, page in enumerate(doc):\n",
        "                        text = page.get_text()\n",
        "                        if text:\n",
        "                            all_docs.append(Document(\n",
        "                                page_content=text,\n",
        "                                metadata={\"file_name\": file_name, \"page_number\": i + 1}\n",
        "                            ))\n",
        "            # ✅ NEW: OCR for images and screenshots\n",
        "            # ✅ FIX: Robust OCR for images and screenshots\n",
        "            elif file_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "                image = Image.open(io.BytesIO(file_content))\n",
        "                text = pytesseract.image_to_string(image)\n",
        "                if text and text.strip():\n",
        "                    all_docs.append(Document(\n",
        "                        page_content=text,\n",
        "                        metadata={\"file_name\": file_name, \"type\": \"image_with_text\"}\n",
        "                    ))\n",
        "                else:\n",
        "                    # Fallback if no text is found\n",
        "                    all_docs.append(Document(\n",
        "                        page_content=f\"This is an image named {file_name} that does not contain any readable text.\",\n",
        "                        metadata={\"file_name\": file_name, \"type\": \"image\"}\n",
        "                    ))\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to process file {file_name}: {e}\")\n",
        "\n",
        "    if not all_docs:\n",
        "        raise HTTPException(status_code=400, detail=\"No valid content could be processed from the uploaded files.\")\n",
        "\n",
        "    split_docs = text_splitter.split_documents(all_docs)\n",
        "    # ✅ NEW: Use the client-provided session ID as the namespace\n",
        "    vector_store.add_documents(split_docs, namespace=session_id)\n",
        "    logging.info(f\"Successfully indexed {len(split_docs)} document chunks for session {session_id}.\")\n",
        "    return {\"msg\": f\"Successfully indexed {len(split_docs)} document chunks.\"}\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    query: str\n",
        "    session_id: str\n",
        "\n",
        "@app.post(\"/query/\")\n",
        "async def query(req: QueryRequest):\n",
        "    if not MODELS_LOADED:\n",
        "        raise HTTPException(status_code=503, detail=\"Model services are not available.\")\n",
        "\n",
        "    user_query = req.query.strip().lower()\n",
        "    session_id = req.session_id\n",
        "\n",
        "    if not session_id:\n",
        "        raise HTTPException(status_code=400, detail=\"A session ID is required for querying.\")\n",
        "\n",
        "    conversational_responses = {\n",
        "        \"hello\": \"Hi there! How can I help you with your documents today?\",\n",
        "        \"hi\": \"Hello! I'm ready to answer your questions.\",\n",
        "        \"how are you\": \"I'm just a set of algorithms, but I'm running perfectly! What can I do for you?\",\n",
        "        \"thanks\": \"You're welcome! Let me know if you have any other questions.\",\n",
        "        \"thank you\": \"You're welcome! Is there anything else you need help with?\"\n",
        "    }\n",
        "\n",
        "    if user_query in conversational_responses:\n",
        "        return {\"answer\": conversational_responses[user_query], \"sources\": []}\n",
        "\n",
        "    # ✅ NEW: Use the client-provided session ID for retrieval\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3, \"namespace\": session_id})\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are Spe, an expert assistant designed to assist users with analyzing and understanding content from uploaded files, including PDFs, documents, and images. Your responses must be clear, concise, and strictly based on the provided context, avoiding speculative information, metadata references (e.g., author names, DOIs), or repetitive boilerplate text. Do not include artificial section headers like \"Summary:\" or \"Explanation:\" unless explicitly requested.\n",
        "\n",
        "Response Guidelines:\n",
        "1. **Summarization Queries**: For queries like \"summarize this document\" or \"what is this about,\" provide a concise summary in 4–6 sentences or 4–6 bullet points, capturing all key ideas without redundancy. Focus on the core content, intent, and main topics of the document or image. For images, summarize any extracted text or describe the visual content if no text is present.\n",
        "2. **Text Extraction Queries** (e.g., \"What text is written in this image/page?\"): Return the extracted text accurately, cleaning up OCR noise (e.g., stray characters, misspellings) to ensure readability. Present the text in a clear, formatted manner, such as a list or paragraph.\n",
        "3. **Title/Heading Queries**: Provide the exact title or heading if present in the context. If none exists, state: \"No title or heading is present in the provided content.\"\n",
        "4. **Content Description Queries** (e.g., \"What is this document/pdf/image about?\"): Provide a concise 1–2 sentence explanation of the main topic or purpose, distinguishing between PDFs and images if necessary.\n",
        "5. **Specific Questions**: Answer directly and precisely using only the context. If the context lacks relevant information, respond with: \"The provided content does not contain this information.\"\n",
        "6. **Author Queries**: If author names are explicitly mentioned in the context, list them. Otherwise, respond with: \"The provided content does not mention any author names.\"\n",
        "7. **Image-Specific Queries**: For images, prioritize accurate text extraction using OCR results. If no text is extracted or the text is unreadable, describe the visual elements (e.g., \"The image is a diagram of a bridge structure\") and note the absence of readable text. If the query asks for specific image content (e.g., text, objects), verify the OCR output and correct any obvious errors before responding.\n",
        "\n",
        "General Rules:\n",
        "- Use natural, conversational language, avoiding phrases like \"The text describes\" unless necessary.\n",
        "- Do not repeat information in multiple forms or add unnecessary disclaimers.\n",
        "- Ensure responses are complete, non-repetitive, and directly address the query.\n",
        "- For images, validate OCR output for accuracy and correct errors (e.g., misread characters) to avoid incorrect answers.\n",
        "- Differentiate content types (PDF vs. image) only when relevant to the query.\n",
        "- Maintain a professional yet approachable tone, ensuring clarity and accuracy.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        chain_type_kwargs={\"prompt\": prompt},\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    result = qa_chain.invoke({\"query\": req.query})\n",
        "\n",
        "    raw_answer = result[\"result\"].strip()\n",
        "    clean_answer = raw_answer.split(\"Answer:\")[-1].strip()\n",
        "\n",
        "    source_files = list(set([doc.metadata.get(\"file_name\", \"unknown\") for doc in result[\"source_documents\"]]))\n",
        "\n",
        "    return {\"answer\": clean_answer, \"sources\": source_files}"
      ],
      "metadata": {
        "id": "q7THfGyYNFPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7jNPTZyM2Ac"
      },
      "outputs": [],
      "source": [
        "import uvicorn\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"✅ Your public URL is: {public_url}\")\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6LImmPxuDdP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}